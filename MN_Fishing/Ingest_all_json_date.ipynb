{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def clear_length_variables():\n",
    "    global length_1\n",
    "    global length_2\n",
    "    global length_3\n",
    "    global length_4\n",
    "    global length_5\n",
    "    global length_6\n",
    "    global length_7\n",
    "    global length_8\n",
    "    global length_9\n",
    "    global length_10\n",
    "    global length_11\n",
    "    global length_12\n",
    "    global length_13\n",
    "    global length_14\n",
    "    global length_15\n",
    "    global length_16\n",
    "    global length_17\n",
    "    global length_18\n",
    "    global length_19\n",
    "    global length_20\n",
    "    global length_21\n",
    "    global length_22\n",
    "    global length_23\n",
    "    global length_24\n",
    "    global length_25\n",
    "    global length_26\n",
    "    global length_27\n",
    "    global length_28\n",
    "    global length_29\n",
    "    global length_30\n",
    "    global length_31\n",
    "    global length_32\n",
    "    global length_33\n",
    "    global length_34\n",
    "    global length_35\n",
    "    global length_36\n",
    "    global length_37\n",
    "    global length_38\n",
    "    global length_39\n",
    "    global length_40\n",
    "    global length_41\n",
    "    global length_42\n",
    "    global length_43\n",
    "    global length_44\n",
    "    global length_45\n",
    "    global length_46\n",
    "    global length_47\n",
    "    global length_48\n",
    "    global length_49\n",
    "    global length_50\n",
    "\n",
    "\n",
    "    length_1 = 0\n",
    "    length_2 = 0\n",
    "    length_3 = 0\n",
    "    length_4 = 0\n",
    "    length_5 = 0\n",
    "    length_6 = 0\n",
    "    length_7 = 0\n",
    "    length_8 = 0\n",
    "    length_9 = 0\n",
    "    length_10 = 0\n",
    "    length_11 = 0   \n",
    "    length_12 = 0\n",
    "    length_13 = 0\n",
    "    length_14 = 0\n",
    "    length_15 = 0\n",
    "    length_16 = 0\n",
    "    length_17 = 0\n",
    "    length_18 = 0\n",
    "    length_19 = 0\n",
    "    length_20 = 0\n",
    "    length_21 = 0\n",
    "    length_22 = 0\n",
    "    length_23 = 0\n",
    "    length_24 = 0\n",
    "    length_25 = 0\n",
    "    length_26 = 0\n",
    "    length_27 = 0\n",
    "    length_28 = 0\n",
    "    length_29 = 0\n",
    "    length_30 = 0\n",
    "    length_31 = 0\n",
    "    length_32 = 0\n",
    "    length_33 = 0\n",
    "    length_34 = 0\n",
    "    length_35 = 0\n",
    "    length_36 = 0\n",
    "    length_37 = 0\n",
    "    length_38 = 0\n",
    "    length_39 = 0\n",
    "    length_40 = 0\n",
    "    length_41 = 0\n",
    "    length_42 = 0\n",
    "    length_43 = 0\n",
    "    length_44 = 0\n",
    "    length_45 = 0\n",
    "    length_46 = 0\n",
    "    length_47 = 0\n",
    "    length_48 = 0\n",
    "    length_49 = 0\n",
    "    length_50 = 0\n",
    "\n",
    "def length_variables(inches, fish_count):\n",
    "    global length_1\n",
    "    global length_2\n",
    "    global length_3\n",
    "    global length_4\n",
    "    global length_5\n",
    "    global length_6\n",
    "    global length_7\n",
    "    global length_8\n",
    "    global length_9\n",
    "    global length_10\n",
    "    global length_11\n",
    "    global length_12\n",
    "    global length_13\n",
    "    global length_14\n",
    "    global length_15\n",
    "    global length_16\n",
    "    global length_17\n",
    "    global length_18\n",
    "    global length_19\n",
    "    global length_20\n",
    "    global length_21\n",
    "    global length_22\n",
    "    global length_23\n",
    "    global length_24\n",
    "    global length_25\n",
    "    global length_26\n",
    "    global length_27\n",
    "    global length_28\n",
    "    global length_29\n",
    "    global length_30\n",
    "    global length_31\n",
    "    global length_32\n",
    "    global length_33\n",
    "    global length_34\n",
    "    global length_35\n",
    "    global length_36\n",
    "    global length_37\n",
    "    global length_38\n",
    "    global length_39\n",
    "    global length_40\n",
    "    global length_41\n",
    "    global length_42\n",
    "    global length_43\n",
    "    global length_44\n",
    "    global length_45\n",
    "    global length_46\n",
    "    global length_47\n",
    "    global length_48\n",
    "    global length_49\n",
    "    global length_50\n",
    "\n",
    "    if inches == 1:\n",
    "        length_1 = fish_count\n",
    "    if inches == 2:\n",
    "        length_2 = fish_count\n",
    "    if inches == 3:\n",
    "        length_3 = fish_count\n",
    "    if inches == 4:\n",
    "        length_4 = fish_count\n",
    "    if inches == 5:\n",
    "        length_5 = fish_count\n",
    "    if inches == 6:\n",
    "        length_6 = fish_count\n",
    "    if inches == 7:\n",
    "        length_7 = fish_count\n",
    "    if inches == 8:\n",
    "        length_8 = fish_count\n",
    "    if inches == 9:\n",
    "        length_9 = fish_count\n",
    "    if inches == 10:\n",
    "        length_10 = fish_count\n",
    "    if inches == 11:\n",
    "        length_11 = fish_count\n",
    "    if inches == 12:\n",
    "        length_12 = fish_count\n",
    "    if inches == 13:\n",
    "        length_13 = fish_count\n",
    "    if inches == 14:\n",
    "        length_14 = fish_count\n",
    "    if inches == 15:\n",
    "        length_15 = fish_count\n",
    "    if inches == 16:\n",
    "        length_16 = fish_count\n",
    "    if inches == 17:\n",
    "        length_17 = fish_count\n",
    "    if inches == 18:\n",
    "        length_18 = fish_count\n",
    "    if inches == 19:\n",
    "        length_19 = fish_count\n",
    "    if inches == 20:\n",
    "        length_20 = fish_count\n",
    "    if inches == 21:\n",
    "        length_21 = fish_count\n",
    "    if inches == 22:\n",
    "        length_22 = fish_count\n",
    "    if inches == 23:\n",
    "        length_23 = fish_count\n",
    "    if inches == 24:\n",
    "        length_24 = fish_count\n",
    "    if inches == 25:\n",
    "        length_25 = fish_count\n",
    "    if inches == 26:\n",
    "        length_26 = fish_count\n",
    "    if inches == 27:\n",
    "        length_27 = fish_count\n",
    "    if inches == 28:\n",
    "        length_28 = fish_count\n",
    "    if inches == 29:\n",
    "        length_29 = fish_count\n",
    "    if inches == 30:\n",
    "        length_30 = fish_count\n",
    "    if inches == 31:\n",
    "        length_31 = fish_count\n",
    "    if inches == 32:\n",
    "        length_32 = fish_count\n",
    "    if inches == 33:\n",
    "        length_33 = fish_count\n",
    "    if inches == 34:\n",
    "        length_34 = fish_count\n",
    "    if inches == 35:\n",
    "        length_35 = fish_count\n",
    "    if inches == 36:\n",
    "        length_36 = fish_count\n",
    "    if inches == 37:\n",
    "        length_37 = fish_count\n",
    "    if inches == 38:\n",
    "        length_38 = fish_count\n",
    "    if inches == 39:\n",
    "        length_39 = fish_count\n",
    "    if inches == 40:\n",
    "        length_40 = fish_count\n",
    "    if inches == 41:\n",
    "        length_41 = fish_count\n",
    "    if inches == 42:\n",
    "        length_42 = fish_count\n",
    "    if inches == 43:\n",
    "        length_43 = fish_count\n",
    "    if inches == 44:\n",
    "        length_44 = fish_count\n",
    "    if inches == 45:\n",
    "        length_45 = fish_count\n",
    "    if inches == 46:\n",
    "        length_46 = fish_count\n",
    "    if inches == 47:\n",
    "        length_47 = fish_count\n",
    "    if inches == 48:\n",
    "        length_48 = fish_count\n",
    "    if inches == 49:\n",
    "        length_49 = fish_count\n",
    "    if inches == 50:\n",
    "        length_50 = fish_count\n",
    "        \n",
    "\n",
    "#### BRING IN AND FORMAT ALL LAKES\n",
    "lakes_all2 = pd.read_csv ('all_lakes.csv')\n",
    "lakes_all2['ID'] = lakes_all2['ID'].astype(str)\n",
    "lakes_all2.loc[lakes_all2.County <= 'Carlton', \"ID\"] = \"0\"+lakes_all2.ID\n",
    "\n",
    "survey_details = survey_details_temp\n",
    "catch_summaries = catch_summaries_temp\n",
    "catch_lengths = catch_lengths_temp\n",
    "\n",
    "# truncate survey_details \n",
    "survey_details = survey_details[0:0]\n",
    "catch_summaries = catch_summaries[0:0]\n",
    "catch_lengths = catch_lengths[0:0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'catch_lengths' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 89\u001b[0m\n\u001b[0;32m     76\u001b[0m             length_variables(m[\u001b[38;5;241m0\u001b[39m], m[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m     78\u001b[0m         catch_lengths_temp \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlake_id\u001b[39m\u001b[38;5;124m'\u001b[39m:lake_id,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurveyID\u001b[39m\u001b[38;5;124m'\u001b[39m:surveyID,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspecies\u001b[39m\u001b[38;5;124m'\u001b[39m:species,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaximum_length\u001b[39m\u001b[38;5;124m'\u001b[39m:maximum_length,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mminimum_length\u001b[39m\u001b[38;5;124m'\u001b[39m:minimum_length,\n\u001b[0;32m     79\u001b[0m                         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlength_1\u001b[39m\u001b[38;5;124m'\u001b[39m:length_1,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlength_2\u001b[39m\u001b[38;5;124m'\u001b[39m:length_2,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlength_3\u001b[39m\u001b[38;5;124m'\u001b[39m:length_3,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlength_4\u001b[39m\u001b[38;5;124m'\u001b[39m:length_4,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlength_5\u001b[39m\u001b[38;5;124m'\u001b[39m:length_5,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlength_6\u001b[39m\u001b[38;5;124m'\u001b[39m:length_6,\n\u001b[0;32m     80\u001b[0m                         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlength_7\u001b[39m\u001b[38;5;124m'\u001b[39m:length_7,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlength_8\u001b[39m\u001b[38;5;124m'\u001b[39m:length_8,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlength_9\u001b[39m\u001b[38;5;124m'\u001b[39m:length_9,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlength_10\u001b[39m\u001b[38;5;124m'\u001b[39m:length_10,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlength_11\u001b[39m\u001b[38;5;124m'\u001b[39m:length_11,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlength_12\u001b[39m\u001b[38;5;124m'\u001b[39m:length_12,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     86\u001b[0m                         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlength_43\u001b[39m\u001b[38;5;124m'\u001b[39m:length_43,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlength_44\u001b[39m\u001b[38;5;124m'\u001b[39m:length_44,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlength_45\u001b[39m\u001b[38;5;124m'\u001b[39m:length_45,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlength_46\u001b[39m\u001b[38;5;124m'\u001b[39m:length_46,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlength_47\u001b[39m\u001b[38;5;124m'\u001b[39m:length_47,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlength_48\u001b[39m\u001b[38;5;124m'\u001b[39m:length_48,\n\u001b[0;32m     87\u001b[0m                         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlength_49\u001b[39m\u001b[38;5;124m'\u001b[39m:length_49,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlength_50\u001b[39m\u001b[38;5;124m'\u001b[39m:length_50}, index\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m---> 89\u001b[0m         catch_lengths \u001b[38;5;241m=\u001b[39m \u001b[43mcatch_lengths\u001b[49m\u001b[38;5;241m.\u001b[39mappend(catch_lengths_temp)\n\u001b[0;32m     91\u001b[0m \u001b[38;5;66;03m#catch_summaries\u001b[39;00m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;66;03m# catch_summaries.to_csv(r'catch_summaries.csv', index = False)\u001b[39;00m\n\u001b[0;32m     93\u001b[0m catch_lengths\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcatch_lengths.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'catch_lengths' is not defined"
     ]
    }
   ],
   "source": [
    "import bs4\n",
    "import json\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "\n",
    "#### BRING IN AND FORMAT ALL LAKES\n",
    "# lakes_all2 = pd.read_csv ('all_lakes.csv')\n",
    "# lakes_all2['ID'] = lakes_all2['ID'].astype(str)\n",
    "# lakes_all2.loc[lakes_all2.County <= 'Carlton', \"ID\"] = \"0\"+lakes_all2.ID\n",
    "\n",
    "#tonka = 27013300\n",
    "#parkers = 27010700\n",
    "\n",
    "#i have url that contains json data.  Pull json data from url and list all of the json objects\n",
    "url = \"https://maps2.dnr.state.mn.us/cgi-bin/lakefinder/detail.cgi?type=lake_survey&id=27010700\"\n",
    "page = requests.get(url)\n",
    "soup = bs4.BeautifulSoup(page.text, 'html.parser')\n",
    "json_data = json.loads(str(soup.text))\n",
    "\n",
    "json_data['result']['surveys'][0].keys()\n",
    "# dict_keys([ 'lengths')\n",
    "\n",
    "\n",
    "for i in range(len(json_data['result']['surveys'])):\n",
    "    lake_id = json_data['result']['DOWNumber']\n",
    "    surveyID = json_data['result']['surveys'][i]['surveyID']\n",
    "    surveyType = json_data['result']['surveys'][i]['surveyType']\n",
    "    surveySubType = json_data['result']['surveys'][i]['surveySubType']\n",
    "    surveyDate = json_data['result']['surveys'][i]['surveyDate']\n",
    "    fishCatchSummaries = json_data['result']['surveys'][i]['fishCatchSummaries']\n",
    "    lengths = json_data['result']['surveys'][i]['lengths']\n",
    "    narrative = json_data['result']['surveys'][i]['narrative']\n",
    "\n",
    "    survey_details_temp = pd.DataFrame({'lake_id':lake_id,'surveyID':surveyID,'surveyType':surveyType,'surveySubType':surveySubType,'surveyDate':surveyDate,\n",
    "                    'narrative':narrative}, index=[0])\n",
    "\n",
    "    survey_details = survey_details.append(survey_details_temp)\n",
    "\n",
    "    #Now breaking out all of the fish catch summaries\n",
    "    # dict_keys(['quartileWeight', 'CPUE', 'averageWeight', 'totalWeight', 'gearCount', 'totalCatch', 'quartileCount', 'gear', 'species'])\n",
    "    for j in range(len(json_data['result']['surveys'][i]['fishCatchSummaries'])):\n",
    "        lake_id = json_data['result']['DOWNumber']\n",
    "        species = json_data['result']['surveys'][i]['fishCatchSummaries'][j]['species']\n",
    "        gear = json_data['result']['surveys'][i]['fishCatchSummaries'][j]['gear']\n",
    "        gearCount = json_data['result']['surveys'][i]['fishCatchSummaries'][j]['gearCount']\n",
    "        totalCatch = json_data['result']['surveys'][i]['fishCatchSummaries'][j]['totalCatch']\n",
    "        CPUE = json_data['result']['surveys'][i]['fishCatchSummaries'][j]['CPUE']\n",
    "        totalWeight = json_data['result']['surveys'][i]['fishCatchSummaries'][j]['totalWeight']\n",
    "        averageWeight = json_data['result']['surveys'][i]['fishCatchSummaries'][j]['averageWeight']\n",
    "        quartileCount = json_data['result']['surveys'][i]['fishCatchSummaries'][j]['quartileCount']\n",
    "        quartileWeight = json_data['result']['surveys'][i]['fishCatchSummaries'][j]['quartileWeight']\n",
    "\n",
    "        catch_summaries_temp = pd.DataFrame({'lake_id':lake_id,'surveyID':surveyID,'species':species,'gear':gear,'gearCount':gearCount,'totalCatch':totalCatch,\n",
    "                    'CPUE':CPUE,'totalWeight':totalWeight,'averageWeight':averageWeight,'quartileCount':quartileCount,\n",
    "                    'quartileWeight':quartileWeight}, index=[0])\n",
    "\n",
    "        catch_summaries = catch_summaries.append(catch_summaries_temp)\n",
    "    #Now breaking out all of the length data\n",
    "    for k in json_data['result']['surveys'][i]['lengths'].keys():\n",
    "        species = k\n",
    "        \n",
    "        lake_id = json_data['result']['DOWNumber']\n",
    "        surveyID = json_data['result']['surveys'][i]['surveyID']\n",
    "        \n",
    "        fishcount = json_data['result']['surveys'][i]['lengths'][k]['fishCount']\n",
    "        maximum_length = json_data['result']['surveys'][i]['lengths'][k]['maximum_length']\n",
    "        minimum_length = json_data['result']['surveys'][i]['lengths'][k]['minimum_length']\n",
    "\n",
    "        clear_length_variables()\n",
    "\n",
    "        for m in json_data['result']['surveys'][i]['lengths'][k]['fishCount']:\n",
    "            length_variables(m[0], m[1])\n",
    "\n",
    "        catch_lengths_temp = pd.DataFrame({'lake_id':lake_id,'surveyID':surveyID,'species':species,'maximum_length':maximum_length,'minimum_length':minimum_length,\n",
    "                        'length_1':length_1,'length_2':length_2,'length_3':length_3,'length_4':length_4,'length_5':length_5,'length_6':length_6,\n",
    "                        'length_7':length_7,'length_8':length_8,'length_9':length_9,'length_10':length_10,'length_11':length_11,'length_12':length_12,\n",
    "                        'length_13':length_13,'length_14':length_14,'length_15':length_15,'length_16':length_16,'length_17':length_17,'length_18':length_18,\n",
    "                        'length_19':length_19,'length_20':length_20,'length_21':length_21,'length_22':length_22,'length_23':length_23,'length_24':length_24,\n",
    "                        'length_25':length_25,'length_26':length_26,'length_27':length_27,'length_28':length_28,'length_29':length_29,'length_30':length_30,\n",
    "                        'length_31':length_31,'length_32':length_32,'length_33':length_33,'length_34':length_34,'length_35':length_35,'length_36':length_36,\n",
    "                        'length_37':length_37,'length_38':length_38,'length_39':length_39,'length_40':length_40,'length_41':length_41,'length_42':length_42,\n",
    "                        'length_43':length_43,'length_44':length_44,'length_45':length_45,'length_46':length_46,'length_47':length_47,'length_48':length_48,\n",
    "                        'length_49':length_49,'length_50':length_50}, index=[0])\n",
    "        \n",
    "        catch_lengths = catch_lengths.append(catch_lengths_temp)\n",
    "\n",
    "#catch_summaries\n",
    "# catch_summaries.to_csv(r'catch_summaries.csv', index = False)\n",
    "catch_lengths.to_csv(r'catch_lengths.csv', index = False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lake_list = lakes_all2['ID'].tolist()\n",
    "counter=0\n",
    "\n",
    "for lake_id in lake_list:\n",
    "\n",
    "    url = f\"https://maps2.dnr.state.mn.us/cgi-bin/lakefinder/detail.cgi?type=lake_survey&id={lake_id}\"\n",
    "    page = requests.get(url)\n",
    "    soup = bs4.BeautifulSoup(page.text, 'html.parser')\n",
    "    json_data = json.loads(str(soup.text))\n",
    "\n",
    "    counter += 1\n",
    "    if counter % 10 == 0:\n",
    "        print(counter)\n",
    "        print(f\"Starting: {url}\")\n",
    "\n",
    "    try:\n",
    "        lakeName = json_data['result']['lakeName']\n",
    "    except Exception:\n",
    "        print(f\"No survey for: {lake_id}\")\n",
    "        continue\n",
    "    \n",
    "    for i in range(len(json_data['result']['surveys'])):\n",
    "        lake_id = json_data['result']['DOWNumber']\n",
    "        surveyID = json_data['result']['surveys'][i]['surveyID']\n",
    "        surveyType = json_data['result']['surveys'][i]['surveyType']\n",
    "        surveySubType = json_data['result']['surveys'][i]['surveySubType']\n",
    "        surveyDate = json_data['result']['surveys'][i]['surveyDate']\n",
    "        fishCatchSummaries = json_data['result']['surveys'][i]['fishCatchSummaries']\n",
    "        lengths = json_data['result']['surveys'][i]['lengths']\n",
    "        narrative = json_data['result']['surveys'][i]['narrative']\n",
    "\n",
    "        survey_details_temp = pd.DataFrame({'lake_id':lake_id,'surveyID':surveyID,'surveyType':surveyType,'surveySubType':surveySubType,'surveyDate':surveyDate,\n",
    "                        'narrative':narrative}, index=[0])\n",
    "\n",
    "        survey_details = survey_details.append(survey_details_temp)\n",
    "\n",
    "        #Now breaking out all of the fish catch summaries\n",
    "        # dict_keys(['quartileWeight', 'CPUE', 'averageWeight', 'totalWeight', 'gearCount', 'totalCatch', 'quartileCount', 'gear', 'species'])\n",
    "        for j in range(len(json_data['result']['surveys'][i]['fishCatchSummaries'])):\n",
    "            lake_id = json_data['result']['DOWNumber']\n",
    "            species = json_data['result']['surveys'][i]['fishCatchSummaries'][j]['species']\n",
    "            gear = json_data['result']['surveys'][i]['fishCatchSummaries'][j]['gear']\n",
    "            gearCount = json_data['result']['surveys'][i]['fishCatchSummaries'][j]['gearCount']\n",
    "            totalCatch = json_data['result']['surveys'][i]['fishCatchSummaries'][j]['totalCatch']\n",
    "            CPUE = json_data['result']['surveys'][i]['fishCatchSummaries'][j]['CPUE']\n",
    "            totalWeight = json_data['result']['surveys'][i]['fishCatchSummaries'][j]['totalWeight']\n",
    "            averageWeight = json_data['result']['surveys'][i]['fishCatchSummaries'][j]['averageWeight']\n",
    "            quartileCount = json_data['result']['surveys'][i]['fishCatchSummaries'][j]['quartileCount']\n",
    "            quartileWeight = json_data['result']['surveys'][i]['fishCatchSummaries'][j]['quartileWeight']\n",
    "\n",
    "            catch_summaries_temp = pd.DataFrame({'lake_id':lake_id,'surveyID':surveyID,'species':species,'gear':gear,'gearCount':gearCount,'totalCatch':totalCatch,\n",
    "                        'CPUE':CPUE,'totalWeight':totalWeight,'averageWeight':averageWeight,'quartileCount':quartileCount,\n",
    "                        'quartileWeight':quartileWeight}, index=[0])\n",
    "\n",
    "            catch_summaries = catch_summaries.append(catch_summaries_temp)\n",
    "        #Now breaking out all of the length data\n",
    "        for k in json_data['result']['surveys'][i]['lengths'].keys():\n",
    "            species = k\n",
    "            \n",
    "            lake_id = json_data['result']['DOWNumber']\n",
    "            surveyID = json_data['result']['surveys'][i]['surveyID']\n",
    "            \n",
    "            fishcount = json_data['result']['surveys'][i]['lengths'][k]['fishCount']\n",
    "            maximum_length = json_data['result']['surveys'][i]['lengths'][k]['maximum_length']\n",
    "            minimum_length = json_data['result']['surveys'][i]['lengths'][k]['minimum_length']\n",
    "\n",
    "            clear_length_variables()\n",
    "\n",
    "            for m in json_data['result']['surveys'][i]['lengths'][k]['fishCount']:\n",
    "                length_variables(m[0], m[1])\n",
    "\n",
    "            catch_lengths_temp = pd.DataFrame({'lake_id':lake_id,'surveyID':surveyID,'species':species,'maximum_length':maximum_length,'minimum_length':minimum_length,\n",
    "                            'length_1':length_1,'length_2':length_2,'length_3':length_3,'length_4':length_4,'length_5':length_5,'length_6':length_6,\n",
    "                            'length_7':length_7,'length_8':length_8,'length_9':length_9,'length_10':length_10,'length_11':length_11,'length_12':length_12,\n",
    "                            'length_13':length_13,'length_14':length_14,'length_15':length_15,'length_16':length_16,'length_17':length_17,'length_18':length_18,\n",
    "                            'length_19':length_19,'length_20':length_20,'length_21':length_21,'length_22':length_22,'length_23':length_23,'length_24':length_24,\n",
    "                            'length_25':length_25,'length_26':length_26,'length_27':length_27,'length_28':length_28,'length_29':length_29,'length_30':length_30,\n",
    "                            'length_31':length_31,'length_32':length_32,'length_33':length_33,'length_34':length_34,'length_35':length_35,'length_36':length_36,\n",
    "                            'length_37':length_37,'length_38':length_38,'length_39':length_39,'length_40':length_40,'length_41':length_41,'length_42':length_42,\n",
    "                            'length_43':length_43,'length_44':length_44,'length_45':length_45,'length_46':length_46,'length_47':length_47,'length_48':length_48,\n",
    "                            'length_49':length_49,'length_50':length_50}, index=[0])\n",
    "            \n",
    "            catch_lengths = catch_lengths.append(catch_lengths_temp)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_details.to_csv(r'survey_details.csv', index = False)\n",
    "catch_summaries.to_csv(r'catch_summaries.csv', index = False)\n",
    "catch_lengths.to_csv(r'catch_lengths.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lake_list = lakes_all2['ID'].tolist()\n",
    "counter=0\n",
    "\n",
    "for lake_id in lake_list:\n",
    "\n",
    "    url = f\"https://maps2.dnr.state.mn.us/cgi-bin/lakefinder/detail.cgi?type=lake_survey&id={lake_id}\"\n",
    "    page = requests.get(url)\n",
    "    soup = bs4.BeautifulSoup(page.text, 'html.parser')\n",
    "    json_data = json.loads(str(soup.text))\n",
    "\n",
    "    counter += 1\n",
    "    if counter % 10 == 0:\n",
    "        print(counter)\n",
    "        print(f\"Starting: {url}\")\n",
    "\n",
    "    try:\n",
    "        lakeName = json_data['result']['lakeName']\n",
    "    except Exception:\n",
    "        print(f\"No survey for: {lake_id}\")\n",
    "        continue\n",
    "\n",
    "    #pull out the json data for each column\n",
    "    ###lake_id = json_data['result']['DOWNumber']\n",
    "    lakeName = json_data['result']['lakeName']\n",
    "    officeCode = json_data['result']['officeCode']\n",
    "    maxDepthFeet = json_data['result']['maxDepthFeet']\n",
    "    areaAcres = json_data['result']['areaAcres']\n",
    "    shoreLengthMiles = json_data['result']['shoreLengthMiles']\n",
    "    meanDepthFeet = json_data['result']['meanDepthFeet']\n",
    "    littoralAcres = json_data['result']['littoralAcres']\n",
    "    averageWaterClarity = json_data['result']['averageWaterClarity']\n",
    "\n",
    "    #insert each dataframe column with the appropriate json data\n",
    "    lake_details_temp = pd.DataFrame({'lake_id':lake_id,'lakeName':lakeName,'officeCode':officeCode,'maxDepthFeet':maxDepthFeet,'areaAcres':areaAcres,\n",
    "                                'shoreLengthMiles':shoreLengthMiles,'meanDepthFeet':meanDepthFeet,'littoralAcres':littoralAcres,'averageWaterClarity':averageWaterClarity}, index=[0])\n",
    "\n",
    "    lake_details = lake_details.append(lake_details_temp)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
